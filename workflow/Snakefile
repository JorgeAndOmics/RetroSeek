import os
import math
import pandas as pd

from scripts import defaults

def retrieve_species_list(csv_path:str, default:list[str]=None) -> list[str]:
    if os.path.exists(csv_path):
        return pd.read_csv(csv_path)["species"].unique().tolist()
    else:
        return default


BLAST_DB_EXT = ['ndb', 'nhr', 'nin', 'not', 'nsq', 'ntf', 'nto']
LTR_INDEX_EXT = ['des', 'esq', 'lcp', 'llv', 'md5', 'prj', 'sds', 'ssp', 'suf']
BLAST_OUTPUT_EXT = ['csv', 'parquet']
SPECIES = defaults.SPECIES
SPECIES_POST = retrieve_species_list(
    csv_path=os.path.join(defaults.PATH_DICT['TABLE_OUTPUT_DIR'],'full_genome_blast.csv'),
    default=defaults.SPECIES
)

configfile: defaults.CONFIG_FILE


rule genome_downloader_setup:
    output:
        species=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}.fa')
    params:
        SPECIES_DB=defaults.PATH_DICT['SPECIES_DB'],
        DOWNLOAD_LOG=defaults.PATH_DICT['DOWNLOAD_LOG']
    threads:
        workflow.cores / 3
    shell:
        '''
        bash scripts/genome_downloader.sh {wildcards.genome:q} {params.SPECIES_DB:q} {params.DOWNLOAD_LOG:q}
        '''


rule genome_downloader:
    input:
        species=expand(os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}.fa'), genome=SPECIES)


rule pfam_hmm_downloader:
    output:
        md5=os.path.join(defaults.PATH_DICT['HMM_PROFILE_DIR'], 'md5sum.txt'),
        hmm=os.path.join(defaults.PATH_DICT['HMM_PROFILE_DIR'], 'Pfam-A.hmm')
    params:
        hmm_profile_dir=defaults.PATH_DICT['HMM_PROFILE_DIR'],
        url='https://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/Pfam-A.hmm.gz',
        md5_url='https://ftp.ebi.ac.uk/pub/databases/Pfam/current_release/md5_checksums'
    threads:
        workflow.cores
    shell:
        """
        cd {params.hmm_profile_dir:q} && \
        wget -O {output.hmm:q}.gz {params.url:q} && \
        wget -O {output.md5:q} {params.md5_url:q} && \
        grep "Pfam-A.hmm.gz" {output.md5:q} | md5sum -c - && \
        echo "MD5 checksum for HMM profile is correct. Decompressing..." && \
        gunzip -d -f -v -k {params.hmm_profile_dir:q}/Pfam-A.hmm.gz
        """


rule blast_db_generator_setup:
    input:
        fa = os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}.fa')
    output:
        ndb_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'],'{genome}','{genome}.ndb'),
        nhr_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'],'{genome}','{genome}.nhr'),
        nin_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'],'{genome}','{genome}.nin'),
        not_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'],'{genome}','{genome}.not'),
        nsq_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'],'{genome}','{genome}.nsq'),
        ntf_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'],'{genome}','{genome}.ntf'),
        nto_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'],'{genome}','{genome}.nto')
    params:
        db_dir=defaults.PATH_DICT['SPECIES_DB'],
        optional_params=config['blast'].get('optional_parameters', '')
    threads:
        workflow.cores         # Faster download, not conflicts
    shell:
        """
        find . -maxdepth 1 -type f \( -iname '*.fasta' -o -iname '*.fna' -o -iname '*.fas' -o -iname '*.FASTA' \) \
        | parallel 'mv {{}} "{{.}}.fa"' && \
        makeblastdb -in {input.fa:q} -dbtype nucl {params.optional_params} \
        -out {params.db_dir:q}/{wildcards.genome:q}/{wildcards.genome:q}
        """


rule blast_db_generator:
    input:
        blast_db = expand(os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}/{genome}.{ext}'),
                          genome=SPECIES,
                          ext=BLAST_DB_EXT)


rule ltr_index_generator_setup:
    input:
        fa=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}.fa')
    output:
        des_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}', '{genome}.des'),
        esq_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}', '{genome}.esq'),
        lcp_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}', '{genome}.lcp'),
        llv_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}', '{genome}.llv'),
        md5_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}', '{genome}.md5'),
        prj_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}', '{genome}.prj'),
        sds_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}', '{genome}.sds'),
        ssp_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}', '{genome}.ssp'),
        suf_file=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}', '{genome}.suf')
    params:
        db_dir=defaults.PATH_DICT['SPECIES_DB'],
        suffix_params='-tis -suf -des -ssp -sds -dna -lcp',
        optional_params=config['genome_tools'].get('suffixerator_optional_parameters', ''),
        suffix_array_parts=config['genome_tools'].get('suffix_array_parts', 2)      # We divide by parts because it's a memory-intensive process
    threads: config.get('rule_threads', 1)
    shell:
        """
        echo "Generating suffix array for {wildcards.genome:q}" && \
        gt suffixerator \
        -db {input.fa:q} \
        -indexname {params.db_dir:q}/{wildcards.genome:q}/{wildcards.genome:q} \
        {params.suffix_params} {params.optional_params}\
        -parts {params.suffix_array_parts}
        """


rule ltr_index_generator:
    input:
        idx = expand(os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}', '{genome}.{ext}'),
                     genome=SPECIES,
                     ext=LTR_INDEX_EXT)


rule ltr_harvester_setup:
    input:
        rules.ltr_index_generator.input
    output:
        ltr_fasta = os.path.join(defaults.PATH_DICT['LTRHARVEST_DIR'], '{genome}.fa'),
        ltr_gff3 = os.path.join(defaults.PATH_DICT['LTRHARVEST_DIR'], '{genome}.gff3'),
        ltr_sorted_gff3 = os.path.join(defaults.PATH_DICT['LTRHARVEST_DIR'], '{genome}_sorted.gff3')
    params:
        index_directory_path=defaults.PATH_DICT['SPECIES_DB'],
        output_directory_path=os.path.join(defaults.PATH_DICT['LTRHARVEST_DIR']),
        optional_params=config['genome_tools'].get('ltrharvest_optional_parameters','')
    threads: config.get('rule_threads',1)
    shell:
        '''
        TMPDIR=$(mktemp -d /tmp/ltrharvest_{wildcards.genome}_XXXXXX) && \
        gt ltrharvest \
        -seqids \
        -index {params.index_directory_path:q}/{wildcards.genome:q}/{wildcards.genome:q} \
        -out {params.output_directory_path:q}/{wildcards.genome:q}.fa \
        -gff3 {params.output_directory_path:q}/{wildcards.genome:q}.gff3 \
        {params.optional_params} && \
        gt gff3 -sort {params.output_directory_path:q}/{wildcards.genome:q}.gff3 \
        > {params.output_directory_path:q}/{wildcards.genome:q}_sorted.gff3
        '''


rule ltr_harvester:
    input:
        ltr_files = expand(os.path.join(defaults.PATH_DICT['LTRHARVEST_DIR'], '{genome}.{ext}'),
                           genome=SPECIES,
                           ext=['fa', 'gff3']),
        ltr_sorted_gff3 = expand(os.path.join(defaults.PATH_DICT['LTRHARVEST_DIR'], '{genome}_sorted.{ext}'),
                                 genome=SPECIES,
                                 ext=['gff3'])


rule ltr_digester_setup:
    input:
        ltrharvest_output=rules.ltr_harvester.input.ltr_sorted_gff3,
        pfam_database=rules.pfam_hmm_downloader.output
    output:
        ltr_gff3 = os.path.join(defaults.PATH_DICT['LTRDIGEST_DIR'], '{genome}.gff3')
    params:
        ltr_harvest_path=defaults.PATH_DICT['LTRHARVEST_DIR'],
        hmm_profile_path=defaults.PATH_DICT['HMM_PROFILE_DIR'],
        index_directory_path=defaults.PATH_DICT['SPECIES_DB'],
        output_directory_path=defaults.PATH_DICT['LTRDIGEST_DIR'],
        optional_params=config['genome_tools'].get('ltrdigest_optional_parameters','')
    threads: config.get('rule_threads',1)
    shell:
        '''
        echo "Running LTRDigest for {wildcards.genome:q}" && \
        TMPDIR=$(mktemp -d /tmp/ltrdigest_{wildcards.genome}_XXXXXX) && \
        gt ltrdigest \
        -v -matchdescstart {params.optional_params} \
        -seqfile {params.index_directory_path:q}/{wildcards.genome:q}.fa \
        -hmms {params.hmm_profile_path:q}/Pfam-A.hmm -- \
        {params.ltr_harvest_path:q}/{wildcards.genome:q}_sorted.gff3 \
        {params.index_directory_path:q}/{wildcards.genome:q}/{wildcards.genome:q} \
        > {params.output_directory_path:q}/{wildcards.genome:q}.gff3 && \
        echo "Completed running LTRDigest for {wildcards.genome:q}"
        '''


rule ltr_digester:
    input:
        ltr_files = expand(os.path.join(defaults.PATH_DICT['LTRDIGEST_DIR'], '{genome}.{ext}'),
                           genome=SPECIES, ext=['gff3'])


# TODO: FIX INPUT IN PROBE_EXTRACTOR RULE
rule probe_extractor:
    output:
        probe_pkl=os.path.join(defaults.PATH_DICT['PICKLE_DIR'], 'probe_dict.pkl'),
        probe_csv=os.path.join(defaults.PATH_DICT['TABLE_OUTPUT_DIR'], 'probe_dict.csv'),
        probe_parquet=os.path.join(defaults.PATH_DICT['TABLE_OUTPUT_DIR'], 'probe_dict.parquet')
    params:
        table_dir=defaults.PATH_DICT['TABLE_OUTPUT_DIR']
    threads:
        workflow.cores
    shell:
        '''
        python scripts/probe_extractor.py && \
        python scripts/obj2dict.py --files probe_dict.pkl --output_file_name {params.table_dir}/probe_dict
        '''


rule full_genome_blaster_setup:
    input:
        input_pkl=rules.probe_extractor.output.probe_pkl,
        blast_db=rules.blast_db_generator.output
    output:
        parquet_species=os.path.join(defaults.PATH_DICT['TBLASTN_PICKLE_DIR'], '{genome}.pkl')
    params:
        tblastn_pickle_dir=defaults.PATH_DICT['TBLASTN_PICKLE_DIR'],
        num_threads=1
    threads: config.get('rule_threads',1)
    shell:
        '''
        python scripts/full_genome_blaster.py --genome {wildcards.genome} --num_threads {params.num_threads}
        '''


rule full_genome_blaster:
    input:
        pkl_species=expand(os.path.join(defaults.PATH_DICT['TBLASTN_PICKLE_DIR'],'{genome}.pkl'), genome=SPECIES)


rule blast_pkl2parquet:
    input:
        pkl_species=expand(os.path.join(defaults.PATH_DICT['TBLASTN_PICKLE_DIR'],'{genome}.pkl'), genome=SPECIES)
    output:
        csv_full=os.path.join(defaults.PATH_DICT['TABLE_OUTPUT_DIR'], 'full_genome_blast.csv'),
        parquet_full=os.path.join(defaults.PATH_DICT['TABLE_OUTPUT_DIR'], 'full_genome_blast.parquet')
    params:
        tmp_dir=defaults.PATH_DICT['TMP_DIR'],
        table_output_dir=defaults.PATH_DICT['TABLE_OUTPUT_DIR']
    threads: config.get('rule_threads', 1)
    shell:
        '''
        rm -rf {params.tmp_dir:q} && \
        python scripts/obj2dict.py --files {input.pkl_species:q} --output_file_name {params.table_output_dir:q}/full_genome_blast
        '''

rule species_segmenter_setup:
    input:
        input_parquet = rules.blast_pkl2parquet.output.parquet_full
    output:
        all_parquet=expand(os.path.join(defaults.PATH_DICT['SEGMENTED_SPECIES_DIR'], 'all{suffix}.parquet'),
                           suffix=['_main', '_accessory']),
        species_parquet_full=expand(os.path.join(defaults.PATH_DICT['SEGMENTED_SPECIES_DIR'], '{genome}.parquet'),
                               genome=SPECIES_POST)
    threads: config.get('rule_threads',1)
    params:
        output_dir = defaults.PATH_DICT['SEGMENTED_SPECIES_DIR'],
        config_file = defaults.CONFIG_FILE
    shell:
        'Rscript scripts/species_segmenter.R \
        --input_file {input.input_parquet:q} \
        --output_dir {params.output_dir:q} \
        --config_file {params.config_file:q}'

rule species_segmenter:
    input:
        rules.species_segmenter_setup.output


rule ranges_analysis_setup:
    input:
        original_fasta=expand(os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}.fa'), genome=SPECIES_POST),
        species_segmented=expand(os.path.join(defaults.PATH_DICT['SEGMENTED_SPECIES_DIR'], '{genome}.parquet'),
                                 genome=SPECIES_POST),
        ltr_gff3 = expand(os.path.join(defaults.PATH_DICT['LTRDIGEST_DIR'], '{genome}.gff3'),
                          genome=SPECIES_POST)
    output:
        original_tracks=os.path.join(defaults.PATH_DICT['TRACK_ORIGINAL_DIR'], '{genome}.gff3'),
        original_tracks_reduced=os.path.join(defaults.PATH_DICT['TRACK_ORIGINAL_DIR'],'{genome}_reduced.gff3'),
        candidate_tracks=os.path.join(defaults.PATH_DICT['TRACK_CANDIDATES_DIR'], '{genome}.gff3'),
        candidate_tracks_reduced=os.path.join(defaults.PATH_DICT['TRACK_CANDIDATES_DIR'],'{genome}_reduced.gff3'),
        valid_tracks=os.path.join(defaults.PATH_DICT['TRACK_VALID_DIR'], '{genome}.gff3'),
        valid_tracks_reduced=os.path.join(defaults.PATH_DICT['TRACK_VALID_DIR'],'{genome}_reduced.gff3'),
        # solo_ltr_dir=os.path.join(defaults.PATH_DICT['SOLO_LTR_DIR'],'{genome}.gff3'),
        # flanking_ltr_dir=os.path.join(defaults.PATH_DICT['FLANKING_LTR_DIR'],'{genome}.gff3'),
        overlap_matrix=os.path.join(defaults.PATH_DICT['TABLE_OVERLAP_MATRIX_DIR'],'{genome}.csv'),
        plot_dataframes_full=os.path.join(defaults.PATH_DICT['PLOT_DATAFRAMES_DIR'],'{genome}.parquet'),
        plot_dataframes_main=os.path.join(defaults.PATH_DICT['PLOT_DATAFRAMES_DIR'],'{genome}_main.parquet'),
        plot_dataframes_accessory=os.path.join(defaults.PATH_DICT['PLOT_DATAFRAMES_DIR'],'{genome}_accessory.parquet')
    params:
        species_db=defaults.PATH_DICT['SPECIES_DB'],
        segmented_species_dir=defaults.PATH_DICT['SEGMENTED_SPECIES_DIR'],
        probes_csv=defaults.PROBE_CSV,
        workflow_dir=defaults.PATH_DICT['WORKFLOW_DIR'],
        plot_dataframes_dir=defaults.PATH_DICT['PLOT_DATAFRAMES_DIR'],
        ltr_digest_dir=defaults.PATH_DICT['LTRDIGEST_DIR'],
        yaml_config_file=defaults.CONFIG_FILE,
        original_tracks_dir=defaults.PATH_DICT['TRACK_ORIGINAL_DIR'],
        candidate_tracks_dir=defaults.PATH_DICT['TRACK_CANDIDATES_DIR'],
        valid_tracks_dir=defaults.PATH_DICT['TRACK_VALID_DIR'],
        solo_ltr_dir=defaults.PATH_DICT['SOLO_LTR_DIR'],
        flanking_ltr_dir=defaults.PATH_DICT['FLANKING_LTR_DIR'],
        overlap_matrix_dir=defaults.PATH_DICT['TABLE_OVERLAP_MATRIX_DIR'],
    threads:
        workflow.cores   # Apparently doesn't take well to multicore
    shell:
        '''
        Rscript scripts/ranges_analysis.R \
        --fasta {params.species_db:q}/{wildcards.genome:q}.fa \
        --blast {params.segmented_species_dir:q}/{wildcards.genome:q}.parquet \
        --ltrdigest {params.ltr_digest_dir:q}/{wildcards.genome:q}.gff3 \
        --probes {params.probes_csv:q} \
        --config {params.yaml_config_file:q} \
        --original_ranges {params.original_tracks_dir:q}/{wildcards.genome:q}.gff3 \
        --original_ranges_reduced {params.original_tracks_dir:q}/{wildcards.genome:q}_reduced.gff3 \
        --candidate_ranges {params.candidate_tracks_dir:q}/{wildcards.genome:q}.gff3 \
        --candidate_ranges_reduced {params.candidate_tracks_dir:q}/{wildcards.genome:q}_reduced.gff3 \
        --valid_ranges {params.valid_tracks_dir:q}/{wildcards.genome:q}.gff3 \
        --valid_ranges_reduced {params.valid_tracks_dir:q}/{wildcards.genome:q}_reduced.gff3 \
        --solo_ltr_ranges {params.solo_ltr_dir:q}/{wildcards.genome:q}.gff3 \
        --flanking_ltr_ranges {params.flanking_ltr_dir:q}/{wildcards.genome:q}.gff3 \
        --overlap_matrix {params.overlap_matrix_dir:q}/{wildcards.genome:q}.csv \
        --plot_dataframe {params.plot_dataframes_dir:q}/{wildcards.genome:q}.parquet
        '''


rule ranges_analysis:
    input:
        original_tracks=expand(os.path.join(defaults.PATH_DICT['TRACK_ORIGINAL_DIR'], '{genome}.gff3'),
                               genome=SPECIES_POST),
        original_tracks_reduced=expand(os.path.join(defaults.PATH_DICT['TRACK_ORIGINAL_DIR'],'{genome}.gff3'),
                               genome=SPECIES_POST),
        candidate_tracks=expand(os.path.join(defaults.PATH_DICT['TRACK_CANDIDATES_DIR'],'{genome}.gff3'),
                                genome=SPECIES_POST),
        candidate_tracks_reduced=expand(os.path.join(defaults.PATH_DICT['TRACK_CANDIDATES_DIR'],'{genome}.gff3'),
                                genome=SPECIES_POST),
        valid_tracks=expand(os.path.join(defaults.PATH_DICT['TRACK_VALID_DIR'],'{genome}.gff3'),
                             genome=SPECIES_POST),
        valid_tracks_reduced=expand(os.path.join(defaults.PATH_DICT['TRACK_VALID_DIR'],'{genome}.gff3'),
                                genome=SPECIES_POST),
        # solo_ltr=expand(os.path.join(defaults.PATH_DICT['SOLO_LTR_DIR'],'{genome}.gff3'),
        #                     genome=SPECIES),
        # flanking_ltr=expand(os.path.join(defaults.PATH_DICT['FLANKING_LTR_DIR'],'{genome}.gff3'),
        #                         genome=SPECIES),
        overlap_matrix=expand(os.path.join(defaults.PATH_DICT['TABLE_OVERLAP_MATRIX_DIR'],'{genome}.csv'),
                              genome=SPECIES_POST),
        plot_dataframes_full=expand(os.path.join(defaults.PATH_DICT['PLOT_DATAFRAMES_DIR'],'{genome}.parquet'),
                               genome=SPECIES_POST),
        plot_dataframes_suffixed=expand(os.path.join(defaults.PATH_DICT['PLOT_DATAFRAMES_DIR'],'{genome}{suffix}.parquet'),
                                 genome=SPECIES_POST, suffix=['_main','_accessory'])

rule plot_generator_setup:
    input:
        plot_dataframes=expand(os.path.join(defaults.PATH_DICT['PLOT_DATAFRAMES_DIR'],'{genome}{suffix}.parquet'),
                               genome=SPECIES_POST, suffix=['_main','_accessory'])
    output:
        density_plots=expand(os.path.join(defaults.PATH_DICT['PLOT_DIR'],'{density_probe}_density.png'),
                             density_probe=['main','accessory']),
        raincloud_plots=expand(os.path.join(defaults.PATH_DICT['PLOT_DIR'],'{raincloud_probe}_raincloud.png'),
                               raincloud_probe=['main','accessory']),
        bar_plots=expand(os.path.join(defaults.PATH_DICT['PLOT_DIR'],'{bar_probe}_bar.png'),
                         bar_probe=['full', 'main','accessory']),
        sankey_plots=expand(os.path.join(defaults.PATH_DICT['PLOT_DIR'],'{sankey_probe}_sankey_{plot_type}.png'),
                            sankey_probe=['main','accessory'], plot_type=['a', 'b', 'c']),
        balloon_plots=expand(os.path.join(defaults.PATH_DICT['PLOT_DIR'],'{balloon_probe}_balloon.png'),
                             balloon_probe=['main','accessory'])
    params:
        plot_dataframes_dir=defaults.PATH_DICT['PLOT_DATAFRAMES_DIR'],
        plot_dir=defaults.PATH_DICT['PLOT_DIR'],
        config_yaml = defaults.CONFIG_FILE
    threads:
        workflow.cores
    shell:
        '''
        Rscript scripts/plot2sort.R \
        --input {params.plot_dataframes_dir:q} \
        --output {params.plot_dir:q} \
        --config {params.config_yaml:q}
        '''


rule plot_generator:
    input:
        plots=rules.plot_generator_setup.output


rule circle_plot_generator_setup:
    input:
        fasta=os.path.join(defaults.PATH_DICT['SPECIES_DB'], '{genome}.fa'),
        hits= os.path.join(defaults.PATH_DICT['TRACK_VALID_DIR'], '{genome}_main.gff3'),
        ltrdigest=os.path.join(defaults.PATH_DICT['LTRDIGEST_DIR'], '{genome}.gff3')
    output:
        circle_plot_png=os.path.join(defaults.PATH_DICT['CIRCLE_PLOT_DIR'], '{genome}.png'),
        circle_plot_pdf=os.path.join(defaults.PATH_DICT['CIRCLE_PLOT_DIR'], '{genome}.pdf')

    params:
        species_db=defaults.PATH_DICT['SPECIES_DB'],
        ltrdigest_dir=defaults.PATH_DICT['LTRDIGEST_DIR'],
        valid_tracks_dir=defaults.PATH_DICT['TRACK_VALID_DIR'],
        circle_plot_dir=defaults.PATH_DICT['CIRCLE_PLOT_DIR'],
        config_file=defaults.CONFIG_FILE
    threads:
        workflow.cores
    shell:
        '''
        Rscript scripts/circle_plot_generator.R \
        --fasta {params.species_db:q}/{wildcards.genome:q}.fa \
        --gff_custom {params.valid_tracks_dir:q}/{wildcards.genome:q}_main.gff3 \
        --gff_ltrdigest {params.ltrdigest_dir:q}/{wildcards.genome:q}.gff3 \
        --config {params.config_file:q} \
        --output {params.circle_plot_dir:q}/{wildcards.genome:q}
        '''

rule circle_plot_generator:
    input:
        circle_plots=expand(os.path.join(defaults.PATH_DICT['CIRCLE_PLOT_DIR'], '{genome}.png'),genome=SPECIES_POST)


# TODO: SUFFIX PARSING
rule hotspot_detector_setup:
    input:
        tracks=rules.ranges_analysis.input
    output:
        hotspot_csv=os.path.join(defaults.PATH_DICT['TABLE_HOTSPOT_DIR'], '{genome}.csv'),
        hotspot_histogram_pdf=os.path.join(defaults.PATH_DICT['HOTSPOT_PDF_DIR'], '{genome}_histogram.pdf'),
        hotspot_density_pdf=os.path.join(defaults.PATH_DICT['HOTSPOT_PDF_DIR'], '{genome}_density.pdf'),
        hotspot_heatmap_pdf=os.path.join(defaults.PATH_DICT['HOTSPOT_PDF_DIR'], '{genome}_heatmap.pdf'),
        hotspot_track=os.path.join(defaults.PATH_DICT['TRACK_HOTSPOTS_DIR'], '{genome}.gff3')
    params:
        genomes_dir=defaults.PATH_DICT['SPECIES_DB'],
        input_track_dir=defaults.PATH_DICT['TRACK_ORIGINAL_DIR'],          # For now
        window_size=config.get('hotspot_window_size', 10000),
        mask_size=config.get('hotspot_mask_size', 20),
        mask_mismatch=config.get('hotspot_mask_mismatch', 2),
        permutations=config.get('hotspot_permutations', 3),
        pvalue_threshold=config.get('hotspot_pvalue_threshold', 0.05),
        csv_dir=defaults.PATH_DICT['TABLE_HOTSPOT_DIR'],
        pdf_dir=defaults.PATH_DICT['HOTSPOT_PDF_DIR'],
        track_dir=defaults.PATH_DICT['TRACK_HOTSPOTS_DIR'],
        config_yaml = defaults.CONFIG_FILE
    threads:
        workflow.cores
    shell:
        '''
        Rscript scripts/hotspot_detector.R \
        --fasta {params.genomes_dir:q}/{wildcards.genome}.fa \
        --gff {params.input_track_dir:q}/{wildcards.genome}.gff3 \
        --config {params.config_yaml:q} \
        --csv_output_dir {params.csv_dir:q} \
        --pdf_output_dir {params.pdf_dir:q} \
        --hotspot_output_dir {params.track_dir:q}
        '''

rule hotspot_detector:
    input:
        hotspot_csv=expand(os.path.join(defaults.PATH_DICT['TABLE_HOTSPOT_DIR'], '{genome}.csv'), genome=SPECIES_POST),
        hotspot_histogram_pdf=expand(os.path.join(defaults.PATH_DICT['HOTSPOT_PDF_DIR'], '{genome}_histogram.pdf'), genome=SPECIES_POST),
        hotspot_density_pdf=expand(os.path.join(defaults.PATH_DICT['HOTSPOT_PDF_DIR'], '{genome}_density.pdf'), genome=SPECIES_POST),
        hotspot_heatmap_pdf=expand(os.path.join(defaults.PATH_DICT['HOTSPOT_PDF_DIR'], '{genome}_heatmap.pdf'), genome=SPECIES_POST),
        hotspot_track=expand(os.path.join(defaults.PATH_DICT['TRACK_HOTSPOTS_DIR'], '{genome}.gff3'), genome=SPECIES_POST)


rule pair_detector_setup:
    input:
        gff3_file=os.path.join(defaults.PATH_DICT['TRACK_VALID_DIR'], '{genome}.gff3'),
    output:
        pair_table_csv=os.path.join(defaults.PATH_DICT['TABLE_PAIR_DIR'], '{genome}.csv'),
        pair_table_parquet=os.path.join(defaults.PATH_DICT['TABLE_PAIR_DIR'], '{genome}.parquet')
    params:
        config_yaml=defaults.CONFIG_FILE,
        table_output_dir=defaults.PATH_DICT['TABLE_PAIR_DIR']
    threads:
        workflow.cores
    shell:
        '''
        Rscript scripts/pair_detector.R \
        --config {params.config_yaml:q} \
        --gff {input.gff3_file:q} \
        --table_output_dir {params.table_output_dir:q}
        '''

rule pair_detector:
    input:
        pair_table=expand(os.path.join(defaults.PATH_DICT['TABLE_PAIR_DIR'], '{genome}.csv'), genome=SPECIES_POST)