import defaults
import os

FA_FILES = glob_wildcards(os.path.join(defaults.SPECIES_DB, '{genome}.fa'))
BLAST_DB_EXT = ['ndb', 'nhr', 'nin', 'not', 'nsq', 'ntf', 'nto']
LTR_INDEX_EXT = ['des', 'esq', 'lcp', 'llv', 'md5', 'prj', 'sds', 'ssp', 'suf']
BLAST_OUTPUT_EXT = ['csv', 'parquet']


rule fa_converter:
    params:
        SPECIES_DB=defaults.SPECIES_DB
    shell:
        """
        for file in *.fasta *.fna; do
        mv "$file" "${{file%.*}}.fa"
        done
        """

rule blast_db_generator:
    input:
        blast_db = expand(os.path.join(defaults.SPECIES_DB, '{genome}/{genome}.{ext}'), genome=defaults.SPECIES, ext=BLAST_DB_EXT)

rule blast_db_generator_setup:
    input:
        fa = os.path.join(defaults.SPECIES_DB, '{genome}.fa')
    output:
        ndb_file=os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.ndb'),
        nhr_file=os.path.join(defaults.SPECIES_DB,'{genome}','{genome}.nhr'),
        nin_file=os.path.join(defaults.SPECIES_DB,'{genome}','{genome}.nin'),
        not_file=os.path.join(defaults.SPECIES_DB,'{genome}','{genome}.not'),
        nsq_file=os.path.join(defaults.SPECIES_DB,'{genome}','{genome}.nsq'),
        ntf_file=os.path.join(defaults.SPECIES_DB,'{genome}','{genome}.ntf'),
        nto_file=os.path.join(defaults.SPECIES_DB,'{genome}','{genome}.nto'),
    params:
        db_dir=defaults.SPECIES_DB
    threads:
        workflow.cores
    shell:
        """
        makeblastdb -in {input.fa} -dbtype nucl -parse_seqids -out {params.db_dir}/{wildcards.genome}/{wildcards.genome}
        """

rule virus_blast_db_generator:
    input:
        blast_db = expand(os.path.join(defaults.VIRUS_DB, '{db}/{db}.{ext}'), db=defaults.VIRUS, ext=BLAST_DB_EXT)

rule virus_blast_db_generator_setup:
    input:
        fa = os.path.join(defaults.VIRUS_DB, '{db}.fa')
    output:
        blast_db = expand(os.path.join(defaults.VIRUS_DB, '{db}/{db}.{ext}'), db=defaults.VIRUS, ext=BLAST_DB_EXT)
    params:
        db_dir=defaults.VIRUS_DB
    threads:
        workflow.cores
    shell:
        """
        makeblastdb -in {input.fa} -dbtype nucl -parse_seqids -out {params.db_dir}/{wildcards.db}/{wildcards.db}
        """

rule ltr_index_generator:
    input:
        idx = expand(os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.{ext}'), genome=defaults.SPECIES, ext=LTR_INDEX_EXT)

rule ltr_index_generator_setup:
    input:
        fa=os.path.join(defaults.SPECIES_DB, '{genome}.fa')
    output:
        os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.des'),
        os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.esq'),
        os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.lcp'),
        os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.llv'),
        os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.md5'),
        os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.prj'),
        os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.sds'),
        os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.ssp'),
        os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.suf')
    params:
        db_dir=defaults.SPECIES_DB,
        main_suffix_params='-tis -suf -des -ssp -sds -dna',
        lcp_suffix_params='-lcp'
    threads:
        workflow.cores
    shell:
        """
        gt -j {workflow.cores} suffixerator \
        -v -showprogress \
        -db {input.fa} \
        -indexname {params.db_dir}/{wildcards.genome}/{wildcards.genome} \
        {params.main_suffix_params} && \
        gt suffixerator \
        -showprogress \
        -db {input.fa} \
        -indexname {params.db_dir}/{wildcards.genome}/{wildcards.genome} \
        {params.lcp_suffix_params}
        """

rule ltr_harvester:
    input:
        ltr_files = expand(os.path.join(defaults.LTRHARVEST_DIR, '{genome}.{ext}'), genome=defaults.SPECIES, ext=['fa', 'gff3']),
        ltr_sorted_gff3 = expand(os.path.join(defaults.LTRHARVEST_DIR, '{genome}_sorted.{ext}'), genome=defaults.SPECIES, ext=['gff3'])

rule ltr_harvester_setup:
    input:
        rules.ltr_index_generator_setup.output
    output:
        ltr_fasta = os.path.join(defaults.LTRHARVEST_DIR, '{genome}.fa'),
        ltr_gff3 = os.path.join(defaults.LTRHARVEST_DIR, '{genome}.gff3'),
        ltr_sorted_gff3 = os.path.join(defaults.LTRHARVEST_DIR, '{genome}_sorted.gff3')
    params:
        index_directory_path=defaults.SPECIES_DB,
        output_directory_path=os.path.join(defaults.LTRHARVEST_DIR)
    shell:
        '''
        gt -j {workflow.cores} ltrharvest \
        -seqids \
        -index {params.index_directory_path}/{wildcards.genome}/{wildcards.genome} \
        -out {params.output_directory_path}/{wildcards.genome}.fa \
        -gff3 {params.output_directory_path}/{wildcards.genome}.gff3 && \
        gt gff3 \
        -sort \
        {params.output_directory_path}/{wildcards.genome}.gff3 > {params.output_directory_path}/{wildcards.genome}_sorted.gff3
        '''

rule ltr_digester:
    input:
        ltr_files = expand(os.path.join(defaults.LTRDIGEST_DIR, '{genome}.{ext}'), genome=defaults.SPECIES, ext=['gff3']),

rule ltr_digester_setup:
    input:
        rules.ltr_harvester_setup.output.ltr_sorted_gff3
    output:
        ltr_gff3 = os.path.join(defaults.LTRDIGEST_DIR, '{genome}.gff3'),
    params:
        ltr_harvest_path=defaults.LTRHARVEST_DIR,
        hmm_profile_path=defaults.HMM_PROFILE_DIR,
        index_directory_path=defaults.SPECIES_DB,
        output_directory_path=defaults.LTRDIGEST_DIR
    shell:
        # TODO: Should I keep the -o argument?
        '''
        gt ltrdigest \ 
        -v -matchdescstart \
        -seqfile {params.index_directory_path}/{wildcards.genome}.fa \
        -hmms {params.hmm_profile_path}/Pfam-A.hmm -- \
        {params.ltr_harvest_path}/{wildcards.genome}_sorted.gff3 \
        {params.index_directory_path}/{wildcards.genome}/{wildcards.genome} \
        -o {params.index_directory_path}/{wildcards.genome} \
        > {params.output_directory_path}/{wildcards.genome}.gff3      
        '''

rule ltr_blast_db:
    input:
        ltr_fasta = expand(os.path.join(defaults.LTR_DB, '{genome}/{genome}.{ext}'), genome=defaults.SPECIES, ext=BLAST_DB_EXT)

rule ltr_blast_db_setup:
    input:
        ltr_fasta = rules.ltr_harvester_setup.output.ltr_fasta
    output:
        os.path.join(defaults.LTR_DB,'{genome}','{genome}.ndb'),
        os.path.join(defaults.LTR_DB,'{genome}','{genome}.nhr'),
        os.path.join(defaults.LTR_DB,'{genome}','{genome}.nin'),
        os.path.join(defaults.LTR_DB,'{genome}','{genome}.not'),
        os.path.join(defaults.LTR_DB,'{genome}','{genome}.nsq'),
        os.path.join(defaults.LTR_DB,'{genome}','{genome}.ntf'),
        os.path.join(defaults.LTR_DB,'{genome}','{genome}.nto'),
    params:
        db_dir = defaults.LTR_DB,

    shell:
        """
        makeblastdb -in {input.ltr_fasta} -dbtype nucl -out {params.db_dir}/{wildcards.genome}/{wildcards.genome}
        """


rule probe_extractor:
    input:
        probe_table=os.path.join(defaults.TABLE_INPUT_DIR, 'Probe_info.csv')
    output:
        probe_pkl=os.path.join(defaults.PICKLE_DIR, 'probe_dict.pkl')
    threads:
        workflow.cores
    shell:
        'python probe_extractor.py && python obj2dict.py --file probe_dict.pkl'

rule full_genome_blaster:
    input:
        pkl = os.path.join(defaults.PICKLE_DIR, 'full_genome_blast.pkl'),
        table = expand(os.path.join(defaults.TABLE_OUTPUT_DIR, 'full_genome_blast.{ext}'), ext = BLAST_OUTPUT_EXT),

rule full_genome_blaster_setup:
    input:
        input_pkl = rules.probe_extractor.output.probe_pkl,
        blast_db = expand(os.path.join(defaults.SPECIES_DB, '{genome}', '{genome}.{ext}'), genome=FA_FILES.genome, ext=BLAST_DB_EXT)
    output:
        pkl = os.path.join(defaults.PICKLE_DIR, 'full_genome_blast.pkl'),
        csv = os.path.join(defaults.TABLE_OUTPUT_DIR, 'full_genome_blast.csv'),
        parquet = os.path.join(defaults.TABLE_OUTPUT_DIR, 'full_genome_blast.parquet')
    shell:
        'python full_genome_blaster.py && python obj2dict.py --file full_genome_blast.pkl'

rule species_segmenter:
    input:
        species=expand(os.path.join(defaults.SEGMENTED_SPECIES_DIR, '{genome}_{suffix}.parquet'), genome=defaults.SPECIES, suffix=['full', 'main', 'accessory']),

rule species_segmenter_setup:
    input:
        input_parquet = rules.full_genome_blaster_setup.output.parquet,
    output:
        output_parquet = expand(os.path.join(defaults.SEGMENTED_SPECIES_DIR, '{genome}_{suffix}.parquet'), genome=defaults.SPECIES, suffix=['full', 'main', 'accessory']),
    params:
        output_dir = defaults.SEGMENTED_SPECIES_DIR
    shell:
        'Rscript species_segmenter.R {input.input_parquet} {params.output_dir}'

rule ranges_analysis:
    input:
        candidate_tracks=expand(os.path.join(defaults.TRACK_CANDIDATES_DIR,'{genome}_{suffix}.gff3'),genome=defaults.SPECIES,suffix=[
            'full', 'main', 'accessory']),
        validated_tracks=expand(os.path.join(defaults.TRACK_VALIDATED_DIR,'{genome}_{suffix}.gff3'),genome=defaults.SPECIES,suffix=[
            'full', 'main', 'accessory']),
        overlap_matrix=expand(os.path.join(defaults.TABLE_OVERLAP_MATRIX_DIR,'{genome}_{suffix}.csv'),genome=defaults.SPECIES,suffix=[
            'full', 'main', 'accessory']),


rule ranges_analysis_setup:
    input:
        original_fasta=expand(os.path.join(defaults.SPECIES_DB, '{genome}.fa'), genome=defaults.SPECIES),
        species_segmented=expand(os.path.join(defaults.SEGMENTED_SPECIES_DIR, '{genome}_{suffix}.parquet'), genome=defaults.SPECIES, suffix=['full', 'main', 'accessory']),
        ltr_sorted_gff3 = expand(os.path.join(defaults.LTRHARVEST_DIR, '{genome}_sorted.gff3'), genome=defaults.SPECIES)
    output:
        original_tracks=os.path.join(defaults.TRACK_ORIGINAL_DIR,'{genome}_{suffix}.gff3'),
        candidate_tracks=os.path.join(defaults.TRACK_CANDIDATES_DIR,'{genome}_{suffix}.gff3'),
        validated_tracks=os.path.join(defaults.TRACK_VALIDATED_DIR,'{genome}_{suffix}.gff3'),
        overlap_matrix=os.path.join(defaults.TABLE_OVERLAP_MATRIX_DIR,'{genome}_{suffix}.csv'),
    params:
        species_db=defaults.SPECIES_DB,
        segmented_species_dir=defaults.SEGMENTED_SPECIES_DIR,
        ltr_harvest_dir=defaults.LTRHARVEST_DIR,
        original_tracks_dir=defaults.TRACK_ORIGINAL_DIR,
        candidate_tracks_dir=defaults.TRACK_CANDIDATES_DIR,
        validated_tracks_dir=defaults.TRACK_VALIDATED_DIR,
        overlap_matrix_dir=defaults.TABLE_OVERLAP_MATRIX_DIR,
        bitscore_threshold=config.get('bitscore_threshold',100),
        identity_threshold=config.get('identity_threshold',30),
        ltr_resize=config.get('ltr_resize',0)
    shell:
        '''
        Rscript ranges_analysis.R \
        --FASTA={params.species_db}/{wildcards.genome}.fa \
        --enERVate={params.segmented_species_dir}/{wildcards.genome}_{wildcards.suffix}.parquet \
        --LTRharvest={params.ltr_harvest_dir}/{wildcards.genome}_sorted.gff3 \
        --bitscore_threshold={params.bitscore_threshold} \
        --identity_threshold={params.identity_threshold} \
        --ltr_resize={params.ltr_resize} \
        --original_ranges={params.original_tracks_dir}/{wildcards.genome}_{wildcards.suffix}.gff3 \
        --candidate_ranges={params.candidate_tracks_dir}/{wildcards.genome}_{wildcards.suffix}.gff3 \
        --validated_ranges={params.validated_tracks_dir}/{wildcards.genome}_{wildcards.suffix}.gff3 \
        --overlap_matrix={params.overlap_matrix_dir}/{wildcards.genome}_{wildcards.suffix}.csv
        '''

rule full_vs_ltr:
    input:
        table = expand(os.path.join(defaults.TABLE_OUTPUT_DIR, 'full_vs_ltr.{ext}'), ext = BLAST_OUTPUT_EXT),

rule full_vs_ltr_setup:
    input:
        input_pkl = rules.full_genome_blaster_setup.output.pkl,
        ltr_blast_db = expand(os.path.join(defaults.LTR_DB,'{genome}','{genome}.{ext}'),genome=FA_FILES.genome,ext=BLAST_DB_EXT)
    output:
        pkl = os.path.join(defaults.PICKLE_DIR, 'full_vs_ltr.pkl'),
        csv = os.path.join(defaults.TABLE_OUTPUT_DIR, 'full_vs_ltr.csv'),
        parquet = os.path.join(defaults.TABLE_OUTPUT_DIR, 'full_vs_ltr.parquet')
    shell:
        'python full_vs_ltr.py && python obj2dict.py --file full_vs_ltr.pkl'

rule ltr_fasta_blaster:
    input:
        table = expand(os.path.join(defaults.TABLE_OUTPUT_DIR, 'full_fasta_blast.{ext}'),ext=BLAST_OUTPUT_EXT),

rule ltr_fasta_blaster_setup:
    input:
        input_pkl = rules.probe_extractor.output.probe_pkl,
        ltr_blast_db= expand(os.path.join(defaults.LTR_DB,'{genome}','{genome}.{ext}'),genome=FA_FILES.genome,ext=BLAST_DB_EXT)
    output:
        pkl = os.path.join(defaults.PICKLE_DIR, 'full_fasta_blast.pkl'),
        csv = os.path.join(defaults.TABLE_OUTPUT_DIR, 'full_fasta_blast.csv'),
        parquet = os.path.join(defaults.TABLE_OUTPUT_DIR, 'full_fasta_blast.parquet')
    shell:
        'python full_vs_ltr.py && python obj2dict.py --file full_fasta_blast.pkl'

rule virus_blaster:
    input:
        table = expand(os.path.join(defaults.TABLE_OUTPUT_DIR, 'virus_blastn_results.{ext}'), ext = BLAST_OUTPUT_EXT),

rule virus_blaster_setup:
    input:
        input_pkl = rules.full_vs_ltr_setup.output.pkl,
        blast_db = expand(os.path.join(defaults.VIRUS_DB, '{db}/{db}.{ext}'), db=defaults.VIRUS, ext=BLAST_DB_EXT)
    output:
        pkl = os.path.join(defaults.PICKLE_DIR, 'virus_blastn_results.pkl'),
        csv = os.path.join(defaults.TABLE_OUTPUT_DIR, 'virus_blastn_results.csv'),
        parquet = os.path.join(defaults.TABLE_OUTPUT_DIR, 'virus_blastn_results.parquet')
    shell:
        'python virus_blaster.py && python obj2dict.py --file virus_blastn_results.pkl'

